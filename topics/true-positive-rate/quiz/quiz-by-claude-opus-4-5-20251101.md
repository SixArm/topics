# True positive rate (TPR)

Question: What does true positive rate (TPR) measure in machine learning model evaluation?

- [ ] The proportion of negative instances correctly identified as negative out of all negative instances
- [ ] The proportion of positive predictions that are actually correct out of all positive predictions
- [ ] The proportion of actual positive instances correctly identified by the model out of all actual positive instances
- [ ] The overall accuracy of the model across both positive and negative predictions

<details>
  <summary>Answer</summary>
  <p>The proportion of actual positive instances correctly identified by the model out of all actual positive instances</p>
  <p>True positive rate (also known as sensitivity, recall, or hit rate) is calculated as True Positives divided by (True Positives + False Negatives). This metric is particularly important in scenarios where missing positive instances has high costs, such as medical diagnostics where failing to identify individuals with a condition can have serious consequences.</p>
</details>
