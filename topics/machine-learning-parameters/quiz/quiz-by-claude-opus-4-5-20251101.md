# Machine learning parameters

Question: What is the fundamental distinction between parameters and hyperparameters in machine learning?

- [ ] Parameters are set before training while hyperparameters are learned from data
- [ ] Parameters are learned from training data while hyperparameters are set before training
- [ ] Parameters and hyperparameters are the same thing with different names
- [ ] Parameters only apply to neural networks while hyperparameters apply to all algorithms

<details>
  <summary>Answer</summary>
  <p>Parameters are learned from training data while hyperparameters are set before training</p>
  <p>Parameters (such as weights, biases, and coefficients) are internal variables that the model learns automatically during the training process by optimizing against the training data. In contrast, hyperparameters (such as learning rate, number of trees, or maximum depth) are configuration settings that must be specified before training begins and control how the learning process operates.</p>
</details>
