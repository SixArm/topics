# Explainable Artificial Intelligence (XAI)

Question: What is the primary distinction between local and global explanations in Explainable AI?

- [ ] Local explanations focus on real-time processing while global explanations focus on batch processing
- [ ] Local explanations explain individual predictions showing how specific inputs influenced the output, while global explanations offer insights into the overall behavior across the entire dataset
- [ ] Local explanations are generated before predictions while global explanations are generated after
- [ ] Local explanations are only used for simple models while global explanations are only used for complex models

<details>
  <summary>Answer</summary>
  <p>Local explanations explain individual predictions showing how specific inputs influenced the output, while global explanations offer insights into the overall behavior across the entire dataset</p>
  <p>In XAI, local explanations help users understand why a specific prediction was made for a particular input, while global explanations provide a broader understanding of how the model behaves across all data. This distinction is critical for technology professionals because different use cases require different levels of explanationâ€”debugging a single prediction requires local explanations, while auditing overall model fairness or bias requires global explanations.</p>
</details>
