# Forward propagation

Question: In a neural network, what is the primary purpose of the activation function during forward propagation?

- [ ] To initialize the weights and biases of the network
- [ ] To calculate the error between predicted and actual outputs
- [ ] To introduce non-linearity to the output of neurons
- [ ] To reduce the number of neurons in each layer

<details>
  <summary>Answer</summary>
  <p>To introduce non-linearity to the output of neurons</p>
  <p>The activation function passes the weighted sum through a non-linear transformation, which allows neural networks to learn complex patterns and relationships in data. Without activation functions, a neural network would essentially be a linear regression model regardless of depth, unable to capture non-linear relationships. Common activation functions include ReLU, sigmoid, and tanh.</p>
</details>
