# Base Milestones on Objective Evaluation of Working Systems: Tutorial

## Overview

"Base milestones on objective evaluation of working systems" is Scaled Agile Framework (SAFe) Principle 5. This principle directly challenges the traditional phase-gate development model, where milestones are based on document reviews, status reports, and progress assessments. Instead, SAFe advocates for milestones grounded in objective demonstrations of working systems -- real, integrated, tested solutions that provide tangible evidence of progress and value.

This tutorial equips change technology professionals with the knowledge to implement evidence-based milestones, moving away from document-driven governance toward milestones that genuinely mitigate risk and ensure sound investment decisions.

## Key Concepts

### The Problem with Phase-Gate Milestones

The traditional sequential, phase-gate development model was designed to ensure that investments in new solutions would deliver economic benefits. At each gate, stakeholders review documents -- requirements specifications, design documents, test plans -- and decide whether to continue funding.

However, experience has shown that phase-gate milestones do not mitigate risk as intended:

- **Documents do not prove that a system works.** A perfect requirements document says nothing about whether the solution can actually be built, integrated, and deployed.
- **Phase-gate reviews create false confidence.** Passing a gate feels like progress, but no working software has been demonstrated.
- **Problems are discovered too late.** Major integration, performance, and usability issues often remain hidden until late in development, when they are most expensive to fix.
- **Sunk cost bias accumulates.** By the time problems are discovered, so much has been invested that cancellation feels impossible, even when it would be the economically rational choice.

### Integration Points as Milestones

In Lean-Agile development, integration points serve as objective milestones. At these points:

- The actual working system is demonstrated -- not documents about the system.
- Technical, financial, and fitness-for-purpose evaluations are conducted based on observable evidence.
- Stakeholders can make informed, evidence-based decisions about continuing, redirecting, or canceling investment.

Integration points occur at regular intervals throughout development (at the end of each iteration and each Program Increment), providing frequent opportunities for evaluation rather than a few high-stakes gate reviews.

### Shared Responsibility for Investment Decisions

SAFe emphasizes that business owners, developers, and customers share responsibility for ensuring that investment produces economic benefit. This shared accountability replaces the traditional model where business stakeholders define requirements, developers build to specification, and quality is inspected after the fact.

### Objective Evidence

The word "objective" in this principle is critical. Milestones must be based on:

- Working software that can be demonstrated and tested.
- Measurable outcomes such as performance metrics, user feedback, and defect rates.
- Integration results that show the system works as a whole, not just in isolated components.

Subjective assessments ("the project is 80% complete") and document-based evidence ("the design review was passed") do not qualify.

## Practical Steps for Implementation

1. **Replace document-based gates with demonstration-based milestones.** At each milestone, require a live demonstration of the working system. Stakeholders should interact with the actual solution, not review slides or documents about it.

2. **Establish regular System Demos.** Hold system-level demonstrations at the end of every iteration (or at minimum, every PI). These demos show integrated, tested functionality to business owners and stakeholders.

3. **Define objective evaluation criteria.** Before each milestone, establish clear, measurable criteria for success. These might include: specific user scenarios that must work, performance benchmarks that must be met, or quality thresholds (e.g., zero critical defects).

4. **Make go/no-go decisions based on evidence.** At each milestone, stakeholders should make explicit decisions about continuing, adjusting, or stopping investment. These decisions should be based on what was observed in the working system, not on promises or projections.

5. **Evaluate fitness for purpose.** Beyond technical functionality, assess whether the solution is actually solving the intended customer problem. Use user testing, analytics, and customer feedback to evaluate fitness for purpose at each milestone.

6. **Assess economic viability at each milestone.** Review whether the business case still holds. Has the market changed? Have costs exceeded expectations? Is the Cost of Delay still justified by the expected value? These are economic questions that should be asked regularly.

7. **Enable early termination without stigma.** One of the greatest benefits of evidence-based milestones is the ability to stop or redirect investment early when evidence shows that continuing is not economically justified. Create a culture where stopping a failing initiative is seen as wise stewardship, not failure.

8. **Reduce the interval between milestones.** More frequent milestones mean smaller investments between evaluation points, reducing the maximum possible waste. Aim for milestones at least every PI (8-12 weeks) and ideally at every iteration (2 weeks).

9. **Include technical debt and architecture assessments.** Working software should not just demonstrate features; it should also demonstrate quality. Include assessments of code quality, technical debt, scalability, and maintainability in milestone evaluations.

10. **Train stakeholders in evidence-based evaluation.** Many business stakeholders are accustomed to phase-gate reviews. Help them understand why working software demonstrations are more reliable indicators of progress and risk than document reviews.

## Key Takeaway

Basing milestones on the objective evaluation of working systems replaces the illusion of progress (passing document reviews) with genuine evidence of progress (demonstrating working software). This approach provides superior risk mitigation, enables better investment decisions, and creates shared accountability among business owners, developers, and customers. Change technology professionals should champion this shift by establishing regular system demonstrations, defining objective evaluation criteria, and creating a culture where evidence -- not opinion or optimism -- drives investment decisions.
