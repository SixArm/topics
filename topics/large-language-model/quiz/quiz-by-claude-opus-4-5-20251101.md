# Large Language Model (LLM)

Question: What training technique do Large Language Models use to learn the relationships between words?

- [ ] Reinforcement learning with human feedback
- [ ] Image classification on text datasets
- [ ] Language modeling by predicting the next word in a sequence
- [ ] Clustering algorithms on word embeddings

<details>
  <summary>Answer</summary>
  <p>Language modeling by predicting the next word in a sequence</p>
  <p>LLMs are trained using language modeling, where the model learns to predict the next word or token given the preceding context. This technique enables the model to learn word probabilities and relationships, allowing it to generate coherent and contextually appropriate text.</p>
</details>
