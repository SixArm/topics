# How to interview a user

User interviews are one of the most powerful qualitative research methods available to technology professionals. Whether you are building a new product, improving an existing service, or validating a design decision, talking directly to the people who use your technology provides insights that analytics, surveys, and assumptions cannot replicate. A well-conducted user interview reveals motivations, frustrations, workflows, and mental models that shape how people interact with your product. This tutorial covers the full lifecycle of planning, conducting, and synthesizing user interviews so you can make better, evidence-based decisions.

## Why user interviews matter

User interviews close the gap between what teams believe users want and what users actually need. Quantitative data tells you what is happening; interviews tell you why. They surface unmet needs, reveal workarounds users have invented, and expose pain points that never appear in a bug tracker. For technology teams practicing agile, lean, or design thinking, interviews are the backbone of customer discovery and continuous product improvement.

Interviews are especially valuable at three moments in a product lifecycle:

- **Before building** -- to validate problem statements and explore the opportunity space.
- **During development** -- to test prototypes, prioritize features, and check assumptions.
- **After launch** -- to understand adoption patterns, satisfaction drivers, and churn risks.

## Types of user interviews

Not every interview serves the same purpose. Choosing the right format depends on your research goal, timeline, and the depth of insight you need.

| Type | Purpose | Typical Duration | Best For |
|---|---|---|---|
| Exploratory | Discover problems and opportunities in a broad domain | 45-60 minutes | Early-stage research, new markets |
| Contextual inquiry | Observe users in their real environment while they perform tasks | 60-90 minutes | Understanding workflows and workarounds |
| Task-based | Watch a user attempt specific tasks, often with a prototype | 30-45 minutes | Usability validation, design iteration |
| Structured | Ask a fixed set of questions in the same order to every participant | 20-30 minutes | Comparative analysis across segments |
| Semi-structured | Follow a discussion guide but adapt based on responses | 30-60 minutes | Most general-purpose research needs |

Semi-structured interviews offer the best balance of consistency and flexibility for most technology projects and are the default recommendation throughout this tutorial.

## Planning the interview

### Define objectives

Start by writing a clear research question. A strong research question is specific enough to guide your interview guide yet broad enough to leave room for unexpected findings. For example, "How do mid-market procurement managers evaluate and approve new SaaS tools?" is more actionable than "What do users think about our product?"

Align your objectives with your team by sharing the research question with product managers, designers, and engineers before you begin recruiting. This avoids the common mistake of conducting interviews that answer questions nobody on the team actually has.

### Recruit participants

The quality of your insights depends entirely on talking to the right people. Aim for participants who represent your target user segment, not just the most convenient or enthusiastic volunteers. Key recruitment considerations include:

- **Sample size**: Five to eight participants per user segment typically surfaces the majority of unique themes. Diminishing returns set in quickly after that.
- **Diversity**: Vary participants across experience levels, geographies, company sizes, and usage patterns to avoid skewed conclusions.
- **Screening**: Use a short screening questionnaire to confirm that candidates match your target profile before scheduling.
- **Incentives**: Offer appropriate compensation for the participant's time. Gift cards, account credits, or charitable donations are common and effective.

### Create a discussion guide

A discussion guide is not a rigid script. It is a structured outline that ensures you cover your research objectives while leaving room for natural conversation. A typical guide includes:

- **Introduction** (2-3 minutes): Introduce yourself, explain the purpose, set expectations for duration and confidentiality, and ask permission to record.
- **Warm-up questions** (3-5 minutes): Easy background questions that build rapport and provide context about the participant.
- **Core questions** (20-40 minutes): Open-ended questions organized by theme that directly address your research objectives.
- **Wrap-up** (3-5 minutes): Summary, opportunity for the participant to add anything, and thanks.

Write more questions than you will have time to ask, then prioritize. This gives you flexibility to skip lower-priority questions if a participant takes a conversation in a productive but unexpected direction.

## Conducting the interview

### Establish rapport

The first two minutes set the tone for the entire session. Introduce yourself by name, explain your role in plain language, and make clear that you are there to learn from the participant, not to test them. Emphasize that there are no right or wrong answers and that honest, critical feedback is the most helpful thing they can offer.

If you are recording the session, ask for explicit consent and explain how the recording will be used. A simple statement such as "I would like to record so I can focus on our conversation instead of taking notes. The recording will only be shared with my immediate team" is usually sufficient.

### Ask open-ended questions

The phrasing of your questions directly determines the quality of the answers you receive. Open-ended questions invite stories, context, and detail. Closed questions produce yes-or-no answers that rarely reveal anything new.

| Weak Question | Stronger Alternative | Why It Is Better |
|---|---|---|
| Do you like the dashboard? | Walk me through how you use the dashboard on a typical day. | Elicits behavior and context, not just opinion |
| Is the onboarding easy? | Tell me about your experience getting started with the product. | Avoids leading the participant toward a positive answer |
| Would you use feature X? | How do you currently handle [problem feature X solves]? | Grounds the conversation in real behavior, not speculation |
| Do you have any problems? | What is the most frustrating part of your current workflow? | Focuses on a specific emotional dimension |

Avoid questions that begin with "Would you..." or "Do you think..." because they invite hypothetical answers. People are poor predictors of their own future behavior. Instead, anchor every question in past or present experience.

### Listen actively

Active listening means giving the participant your full attention and demonstrating that you value what they are saying. Practical techniques include:

- **Paraphrase**: Repeat back what you heard in your own words to confirm understanding. "So it sounds like you spend about 30 minutes each morning just reconciling data across three systems, is that right?"
- **Acknowledge emotions**: If a participant expresses frustration or excitement, name it. "It sounds like that was really frustrating" validates their experience and encourages them to share more.
- **Take minimal notes**: Jot down keywords, timestamps, and follow-up prompts. Do not try to transcribe everything in real time, as it splits your attention and breaks eye contact.
- **Be comfortable with silence**: After a participant finishes speaking, wait two to three seconds before responding. People often fill silence with additional detail that they would not have volunteered otherwise.

### Dig deeper with follow-up questions

Surface-level answers are the starting point, not the destination. When a participant gives a brief or vague response, use follow-up probes to reach the underlying motivation or behavior.

- "Can you tell me more about that?"
- "What happened next?"
- "Why was that important to you?"
- "Can you walk me through a specific example?"
- "How did that make you feel?"

The "five whys" technique, borrowed from root cause analysis, is especially effective. Each successive "why" peels back another layer of assumption until you reach the core need or constraint driving the behavior.

### Empathize and seek context

Technology professionals often default to thinking about features and interfaces. Users think about goals, deadlines, and constraints. Bridge that gap by asking questions that explore the participant's broader context:

- What does their typical day look like?
- Who else is involved in the decision or workflow?
- What tools or processes did they use before your product?
- What would success look like for them personally?

This contextual information often matters more than direct product feedback because it reveals the environment in which your product must succeed.

### Respect silence and pauses

Resist the urge to fill every moment of quiet. Silence is productive. A participant who pauses is often processing a complex thought or deciding whether to share something candid. If you jump in with another question, you lose that insight permanently. Train yourself to count silently to five before speaking after a pause. It feels unnatural at first but quickly becomes one of your most effective interviewing techniques.

## Common mistakes to avoid

Even experienced researchers fall into patterns that compromise interview quality. Watch for these pitfalls:

- **Leading questions**: Phrasing that suggests a desired answer ("Don't you think the new design is better?") corrupts your data.
- **Confirmation bias**: Unconsciously steering the conversation toward evidence that supports your existing hypothesis.
- **Talking too much**: A good interview has the participant speaking 80 percent of the time and the interviewer speaking 20 percent.
- **Solving problems in the session**: When a user describes a pain point, the instinct is to explain how you plan to fix it. Resist this. Your job in the interview is to understand, not to pitch.
- **Asking about the future**: Questions like "Would you pay for this?" or "Would you use this feature?" generate unreliable data. Focus on what people do, not what they say they would do.
- **Skipping the pilot**: Always run your discussion guide with one or two practice participants before starting real sessions. This reveals confusing questions, timing issues, and gaps in your guide.

## Synthesizing interview data

### Organize your notes

After each interview, write a brief summary while the conversation is fresh. Capture the participant's key quotes, surprising moments, and your initial impressions. If you recorded the session, timestamp the most important segments so you can revisit them without rewatching the full recording.

### Identify themes

Once you have completed all interviews, review your notes systematically. Affinity mapping is the most common synthesis technique:

- Write each distinct observation or quote on a separate note.
- Group related notes into clusters.
- Label each cluster with a descriptive theme name.
- Prioritize themes by frequency, severity, and strategic importance.

### Share findings

Translate your themes into actionable recommendations for your team. A strong research report includes:

- **Research objective and methodology**: What you set out to learn and how you conducted the study.
- **Participant overview**: Demographics and screening criteria, without revealing personal identities.
- **Key findings**: Three to five themes, each supported by direct quotes and specific examples.
- **Recommendations**: Concrete next steps tied to each finding.
- **Raw data reference**: A link to full notes or recordings for team members who want to go deeper.

Present findings in person when possible. Hearing a participant's actual words, whether read aloud or played from a recording, creates empathy and urgency that a written summary alone cannot achieve.

## Related

To build on the skills covered in this tutorial, explore these related topics: empathy maps for visualizing user attitudes and behaviors, personas for synthesizing interview findings into reusable archetypes, customer discovery for integrating interviews into lean startup methodology, focus groups for gathering feedback from multiple users simultaneously, diary studies for capturing longitudinal user behavior, usability testing for evaluating specific interface designs, contextual inquiry for observing users in their natural environment, and jobs-to-be-done frameworks for structuring the needs that interviews uncover.

## Summary

User interviews are a foundational research method for any technology professional who wants to build products grounded in real human needs rather than assumptions. The process begins with clear objectives, careful participant recruitment, and a well-crafted discussion guide. During the interview, open-ended questions, active listening, thoughtful follow-up probes, and comfort with silence draw out the deep, contextual insights that drive better design and engineering decisions. After the interviews, disciplined synthesis transforms raw conversation into prioritized themes and actionable recommendations. Mastering this skill does not require a research background; it requires genuine curiosity about the people you are building for and the discipline to let their experiences, not your hypotheses, guide the conversation.

## References

- Portigal, Steve. *Interviewing Users: How to Uncover Compelling Insights*. Rosenfeld Media, 2013. A comprehensive practitioner's guide to planning, conducting, and analyzing user interviews.
- Krug, Steve. *Don't Make Me Think*. New Riders, 2014. Covers usability testing and lightweight user research methods for web and application design.
- Fitzpatrick, Rob. *The Mom Test: How to Talk to Customers and Learn If Your Business Is a Good Idea When Everyone Is Lying to You*. CreateSpace, 2013. Practical advice on asking non-leading questions and avoiding false validation.
- Goodman, Elizabeth, Mike Kuniavsky, and Andrea Moed. *Observing the User Experience: A Practitioner's Guide to User Research*. Morgan Kaufmann, 2012. Broad survey of user research methods including interviewing, contextual inquiry, and diary studies.
- Nielsen Norman Group. "When to Use Which User-Experience Research Methods." https://www.nngroup.com/articles/which-ux-research-methods/ -- Framework for selecting the right research method based on project phase and research question.
- Interaction Design Foundation. "User Interviews: How, When, and Why to Conduct Them." https://www.interaction-design.org/literature/article/user-interviews-how-when-and-why-to-conduct-them -- Overview of interview planning, execution, and analysis with practical templates.
